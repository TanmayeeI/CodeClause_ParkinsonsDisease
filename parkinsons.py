# -*- coding: utf-8 -*-
"""Parkinsons.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18A0ex17X_vYZc9XxzNNTYzxyT0gqgSTU
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import pickle

# Load dataset
data = pd.read_csv("parkinsons_data.csv")

# Drop non-feature column
data = data.drop(columns=['name'])

# Features and labels
X = data.drop(columns=['status'])  # Features
y = data['status']                 # Labels (0 = healthy, 1 = Parkinson's)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Save the scaler and model as a tuple
with open("parkinsons_model.pkl", "wb") as f:
    pickle.dump((scaler, model), f)

from flask import Flask, render_template, request
from flask_sqlalchemy import SQLAlchemy
import pickle
import numpy as np
import os

app = Flask(__name__)

# Configure database
basedir = os.getcwd()
db_path = os.path.join(basedir, 'database.db')
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + db_path
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

db = SQLAlchemy(app)

# Load model and scaler
with open('parkinsons_model.pkl', 'rb') as f:
    scaler, model = pickle.load(f)

# List of features (fields)
fields = ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)',
          'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer', 'MDVP:Shimmer(dB)',
          'Shimmer:APQ3', 'Shimmer:APQ5', 'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR',
          'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']

# Define DB model
class Prediction(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    prediction = db.Column(db.String(20))
    data = db.Column(db.Text)  # Store input as CSV string

# Create DB tables
with app.app_context():
    db.create_all()

@app.route('/', methods=['GET', 'POST'])
def index():
    prediction = None
    if request.method == 'POST':
        try:
            # Collect inputs
            input_data = [float(request.form[field]) for field in fields]
            input_scaled = scaler.transform([input_data])
            result = model.predict(input_scaled)[0]
            prediction = 'Positive' if result == 1 else 'Negative'

            # Save to database
            input_str = ",".join(map(str, input_data))
            entry = Prediction(prediction=prediction, data=input_str)
            db.session.add(entry)
            db.session.commit()

        except Exception as e:
            prediction = f"Error: {e}"

    return render_template('index.html', fields=fields, prediction=prediction)

if __name__ == '__main__':
    app.run(debug=True)